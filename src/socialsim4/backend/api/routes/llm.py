# src/socialsim4/backend/api/routes/llm.py
from __future__ import annotations

from typing import Any, List, Optional

from litestar import Router, post
from litestar.connection import Request
from pydantic import BaseModel, Field
from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession

from ...core.database import get_session
from ...dependencies import extract_bearer_token, resolve_current_user
from ...models.user import ProviderConfig

# ğŸ‘‡ å…³é”®ï¼šè¿™é‡Œéœ€è¦ä¸Šå‡ 3 å±‚åˆ° socialsim4ï¼Œç„¶åå†è¿›å…¥ core
from ....core.llm import create_llm_client
from ....core.llm_config import LLMConfig

class GenerateAgentsRequest(BaseModel):
    count: int = Field(5, ge=1, le=50)
    description: str
    # å‰ç«¯ generateAgentsWithAI é‡Œä¼ çš„ provider_id
    provider_id: Optional[int] = None


class GeneratedAgent(BaseModel):
    id: Optional[str] = None
    name: str
    role: Optional[str] = None
    profile: Optional[str] = None
    provider: Optional[str] = None
    model: Optional[str] = None
    properties: dict[str, Any] = {}
    history: dict[str, Any] = {}
    memory: list[Any] = []
    knowledgeBase: list[Any] = []
async def _select_provider(
    session: AsyncSession,
    user_id: int,
    provider_id: Optional[int],
) -> ProviderConfig:
    # ä¼˜å…ˆç”¨å‰ç«¯ä¼ å…¥çš„ provider_id
    if provider_id is not None:
        result = await session.execute(
            select(ProviderConfig).where(
                ProviderConfig.user_id == user_id,
                ProviderConfig.id == provider_id,
            )
        )
        provider = result.scalars().first()
        if provider is None:
            raise RuntimeError("æŒ‡å®šçš„ LLM æä¾›å•†ä¸å­˜åœ¨æˆ–ä¸å±äºå½“å‰ç”¨æˆ·")
    else:
        # å¦åˆ™æ‰¾ config.active çš„é‚£ä¸ªï¼›éƒ½æ²¡æ ‡ active å°±éšä¾¿æŒ‘ä¸€ä¸ª
        result = await session.execute(
            select(ProviderConfig).where(ProviderConfig.user_id == user_id)
        )
        items = result.scalars().all()
        active = [p for p in items if (p.config or {}).get("active")]
        provider = active[0] if len(active) == 1 else (items[0] if items else None)

    if provider is None:
        raise RuntimeError("LLM provider not configured")

    dialect = (provider.provider or "").lower()
    if dialect not in {"openai", "gemini", "mock"}:
        raise RuntimeError("Invalid LLM provider dialect")
    if dialect != "mock" and not provider.api_key:
        raise RuntimeError("LLM API key required")
    if not provider.model:
        raise RuntimeError("LLM model required")

    return provider
@post("/generate_agents")
async def generate_agents(
    request: Request,
    data: GenerateAgentsRequest,
) -> List[GeneratedAgent]:
    """
    POST /llm/generate_agents

    å‰ç«¯çš„ generateAgentsWithAI() å°±æ˜¯è°ƒçš„è¿™ä¸ªæ¥å£ã€‚
    """
    token = extract_bearer_token(request)

    async with get_session() as session:
        current_user = await resolve_current_user(session, token)

        provider = await _select_provider(
            session, current_user.id, data.provider_id
        )

        cfg = LLMConfig(
            dialect=(provider.provider or "").lower(),
            api_key=provider.api_key or "",
            model=provider.model,
            base_url=provider.base_url,
            temperature=0.7,
            top_p=1.0,
            frequency_penalty=0.0,
            presence_penalty=0.0,
            max_tokens=1024,
        )
        llm = create_llm_client(cfg)

        system_prompt = (
            "ä½ æ˜¯ä¸€ä¸ªç¤¾ä¼šæ¨¡æ‹Ÿå¹³å°çš„è§’è‰²ç”ŸæˆåŠ©æ‰‹ã€‚"
            "æ ¹æ®ç”¨æˆ·æä¾›çš„åœºæ™¯æè¿°ï¼Œç”Ÿæˆä¸€ç»„è§’è‰²é…ç½®ï¼Œè¿”å› JSON æ ¼å¼ã€‚"
            "åªè¾“å‡º JSONï¼Œä¸è¦è§£é‡Šæ–‡å­—ã€‚"
            "æ¯ä¸ªè§’è‰²åŒ…å«å­—æ®µï¼šname, role, profile, propertiesã€‚"
        )

        user_prompt = (
            f"è¯·æ ¹æ®ä»¥ä¸‹åœºæ™¯æè¿°ï¼Œç”Ÿæˆ {data.count} ä¸ªå¤šæ ·åŒ–çš„è§’è‰²ï¼š\n\n"
            f"{data.description}\n\n"
            "è¦æ±‚ï¼š\n"
            "1. è§’è‰²ä¹‹é—´èº«ä»½ã€ç«‹åœºã€æ€§æ ¼è¦æœ‰å·®å¼‚ã€‚\n"
            "2. ç›´æ¥è¿”å› JSON æ•°ç»„ï¼Œä¾‹å¦‚ï¼š\n"
            "[\n"
            "  {\"name\": \"å¼ ä¸‰\", \"role\": \"æ‘é•¿\", \"profile\": \"...\", \"properties\": {\"ä¿¡ä»»å€¼\": 70}},\n"
            "  {\"name\": \"æå››\", \"role\": \"å•†äºº\", \"profile\": \"...\", \"properties\": {\"ä¿¡ä»»å€¼\": 45}}\n"
            "]"
        )

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ]

        raw_text = llm.chat(messages)

        import json

        try:
            parsed = json.loads(raw_text)
        except Exception:
            # LLM æ²¡æŒ‰è¦æ±‚è¿”å› JSON æ—¶çš„å…œåº•ï¼Œå‰ç«¯ä¾ç„¶èƒ½è·‘
            parsed = [
                {
                    "name": f"Agent {i+1}",
                    "role": "è§’è‰²",
                    "profile": f"å ä½è§’è‰²ï¼ŒåŸå§‹è¾“å‡ºæ— æ³•è§£æä¸º JSONï¼š{raw_text[:50]}...",
                    "properties": {},
                }
                for i in range(data.count)
            ]

        if isinstance(parsed, dict) and "agents" in parsed:
            items = parsed["agents"]
        else:
            items = parsed

        agents: List[GeneratedAgent] = []
        for i, a in enumerate(items):
            if not isinstance(a, dict):
                continue
            agents.append(
                GeneratedAgent(
                    id=a.get("id") or None,
                    name=a.get("name") or f"Agent {i+1}",
                    role=a.get("role"),
                    profile=a.get("profile"),
                    provider=provider.provider or "backend",
                    model=provider.model or "default",
                    properties=a.get("properties") or {},
                    history=a.get("history") or {},
                    memory=a.get("memory") or [],
                    knowledgeBase=a.get("knowledgeBase") or [],
                )
            )

        # å¦‚æœæ¨¡å‹è¿”å›çš„ä¸è¶³ count ä¸ªï¼Œç®€å•è¡¥é½
        while len(agents) < data.count:
            idx = len(agents)
            agents.append(
                GeneratedAgent(
                    name=f"Agent {idx+1}",
                    role="è§’è‰²",
                    profile=data.description,
                    provider=provider.provider or "backend",
                    model=provider.model or "default",
                )
            )

        return agents
# æš´éœ² /llm å‰ç¼€çš„ Router
router = Router(
    path="/llm",
    route_handlers=[generate_agents],
)
